<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>欢迎光临</title>
  
  <subtitle>https://nghqqa.cn/</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="www.nghqqa.cn/"/>
  <updated>2019-08-06T11:37:21.155Z</updated>
  <id>www.nghqqa.cn/</id>
  
  <author>
    <name>逆光海</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Linux学习</title>
    <link href="www.nghqqa.cn/2019/08/06/Linux%E5%AD%A6%E4%B9%A0/"/>
    <id>www.nghqqa.cn/2019/08/06/Linux学习/</id>
    <published>2019-08-06T11:28:07.000Z</published>
    <updated>2019-08-06T11:37:21.155Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>对于之前写的hadoop伪分布式的安装文章，可能对一些没有Linux基础的读者来说有一些的难度，所以建议大家先了解Linux的一些基础知识在来看之前的文章，可能就会觉得很简单了</p><h2 id="学习建议"><a href="#学习建议" class="headerlink" title="学习建议"></a>学习建议</h2><p>我个人是比较推荐大家可以去b站看看韩顺平老师的Linux教程，可以在b站直接找到，这里放出b站链接</p><p><a href="https://www.bilibili.com/video/av21303002?from=search&amp;seid=3872508779266125537" target="_blank" rel="noopener">https://www.bilibili.com/video/av21303002?from=search&amp;seid=3872508779266125537</a></p><p>视频是18年上传的，但是知识是不会过时的，当然如果大家不想那么系统的了解Linux的话，可以去看看这个老哥的博客文章，这里放出链接</p><p><a href="https://blog.csdn.net/weixin_41710054/article/details/89081599#22_vivim_19" target="_blank" rel="noopener">https://blog.csdn.net/weixin_41710054/article/details/89081599#22_vivim_19</a></p><p>这个文章写的比较的细，基本不知道的命令或者是快捷键都可以去文章中看看，自己看文章学习，可以比看视频省下不少时间，里面的命令可以基本满足正常操作Linux系统的要求。</p><p>好的，本次Linux的学习建议就到这里了，希望大家生活愉快。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;对于之前写的hadoop伪分布式的安装文章，可能对一些没有Linux基础的读者来说有一些的难度，所以建议大家先了解Linux的一些基础知识在
      
    
    </summary>
    
      <category term="自己学习Linux" scheme="www.nghqqa.cn/categories/%E8%87%AA%E5%B7%B1%E5%AD%A6%E4%B9%A0Linux/"/>
    
    
      <category term="Linux" scheme="www.nghqqa.cn/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>hadoop伪分布式安装</title>
    <link href="www.nghqqa.cn/2019/07/25/hadoop%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/"/>
    <id>www.nghqqa.cn/2019/07/25/hadoop伪分布式安装/</id>
    <published>2019-07-25T05:38:40.000Z</published>
    <updated>2019-08-11T08:47:11.572Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本文介绍的主要是Hadoop的伪分布式的搭建以及遇到的相关问题的解决，做一下记录，jdk的安装这里就不做太多的介绍了，相信大家根据网上的安装介绍很快就能安装成功。</p><p>hadoop集群分为3种模型</p><ol><li>单机模型：测试使用 </li><li>伪分布式模型：运行于单机 </li><li>完全分布式模型：适用于多台机器</li></ol><p>以下是使用的环境</p><table><thead><tr><th align="left">操作环境</th><th>主机名</th><th>IP地址</th><th>jdk</th><th align="center">hadoop版本</th><th></th></tr></thead><tbody><tr><td align="left">centos6.8</td><td>hadoop101</td><td>192.168.128.171</td><td>jdk1.8.0_191</td><td align="center">hadoop-2.7.2</td><td></td></tr><tr><td align="left"></td><td></td><td></td><td></td><td align="center"></td><td></td></tr></tbody></table><p>本文中使用的各种包，后续我会进行上传，以方便读者的使用</p><h1 id="安装hadoop"><a href="#安装hadoop" class="headerlink" title="安装hadoop"></a>安装hadoop</h1><h2 id="hadoop上传与解压"><a href="#hadoop上传与解压" class="headerlink" title="hadoop上传与解压"></a>hadoop上传与解压</h2><p>​    当我们配置好自己的虚拟机后，可以自行在网上下载xftp和xshell，来对于自己的虚拟机进行远程上传文件和远程操作，这两款软件对于学生而言都是免费的，大家可以自行在网站上下载，速度可能会有点慢。</p><p>​    当我们下载好这两款软件后，就可以将hadoop的解压包上传至自己的虚拟机上去，我们将解压包上传至/opt/software中，开始解压hadoop，将hadoop解压至/opt/module/中，同时建议将java也解压至/opt/module/中，方便后面的管理。</p><h3 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile</span><br></pre></td></tr></table></figure><p>具体配置</p><p>在/etc/profile的最后面加上，关于vi编辑器的用法可以自行百度一下，简单用法应该几分钟就能学会</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_191</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"></span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-2.7.2</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure><p>在配置环境变量完成后，记得要进行让它生效</p><p>输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><p>即可生效</p><p>可以输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop version</span><br></pre></td></tr></table></figure><p>如果成功则显示</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Hadoop 2.7.2</span><br><span class="line">Subversion Unknown -r Unknown</span><br><span class="line">Compiled by root on 2017-05-22T10:49Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From source with checksum d0fda26633fa762bff87ec759ebe689c</span><br><span class="line">This command was run using /opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar</span><br></pre></td></tr></table></figure><p>到这里hadoop就算是安装好了</p><h1 id="配置hadoop"><a href="#配置hadoop" class="headerlink" title="配置hadoop"></a>配置hadoop</h1><p>在伪分布式里我们只需要改三个配置文件core-site.xml和hdfs-site.xml还有hadoop-env.sh</p><p>这三个文件在hadoop目录下的etc/hadoop文件夹下</p><p><strong>core-site.xml文件包含了NameNode主机地址，监听端口等信息，对于这个伪分布式模型来说，我的主机地址为hadoo101，NameNode默认使用的端口为8020。</strong></p><p>修改core-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://hadoop101:8020&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">        &lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p><strong>hdfs-site.xml用于配置/HDFS的相关属性，例如数据块的副本参数，数据块的副本对于伪分布式来说应该为1</strong></p><p>修改hdfs-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;!-- 指定HDFS副本的数量 --&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p><strong>hadoop-env.sh 由于Hadoop是java进程，所以需要添加jdk</strong></p><p>修改hadoop-env.sh</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_191</span><br></pre></td></tr></table></figure><p>对于伪分布式来说，改这三个配置文件够了。</p><p>在配置文件完成后，我们需要对hadoop进行初始化</p><p>在hadoop-2.7.2的目录下输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs namenode -format</span><br></pre></td></tr></table></figure><p>如果初始化成功的话，一个和下图相似</p><p><img src="http://pv4lxcno2.bkt.clouddn.com/blog/20190725/9c98NJ18De35.png?imageslim" alt="mark"></p><p>到这里hadoop的配置就已经完成了</p><h1 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h1><p>在hadoop-2.7.2目录下输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-dfs.sh</span><br></pre></td></tr></table></figure><p>启动dfs</p><p>输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-yarn.sh</span><br></pre></td></tr></table></figure><p>启动yarn节点</p><p>启动成功应该和下图相似</p><p><img src="http://pv4lxcno2.bkt.clouddn.com/blog/20190725/15Fa0e8qUDCR.png?imageslim" alt="mark"></p><p>到这里我们的集群就算是启动成功了</p><p>我们可以在web端查看HDFS文件系统</p><p><a href="http://192.168.128.171:50070/" target="_blank" rel="noopener">http://192.168.128.171:50070</a></p><p>192.168.128.171是我的ip地址，如果配置的不同，改一下即可</p><p>web端的hdfs文件系统如下图所示</p><p><img src="http://pv4lxcno2.bkt.clouddn.com/blog/20190725/fKgRPKMecBlX.png?imageslim" alt="mark"></p><h1 id="测试集群"><a href="#测试集群" class="headerlink" title="测试集群"></a>测试集群</h1><p>在HDFS文件系统上创建一个input文件夹</p><p>输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /input</span><br></pre></td></tr></table></figure><p>在web端应该可以看到</p><p><img src="http://pv4lxcno2.bkt.clouddn.com/blog/20190725/GK25hp1DN8GK.png?imageslim" alt="mark"></p><p>我们上传一个文件看看</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put LICENSE.txt /input</span><br></pre></td></tr></table></figure><p>LICENSE.txt是hadoop自带的一个TXT文件</p><p>如果上传成功在web端应该可以看到</p><p><img src="http://pv4lxcno2.bkt.clouddn.com/blog/20190725/C4OldlfJiDzs.png?imageslim" alt="mark"></p><p>这样就是上传成功了</p><p>我们在HDFS上跑一下MapReduce程序</p><p>输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /input/LICENSE.txt /output</span><br></pre></td></tr></table></figure><p>这里说明一下MapReduce要在启动yarn下运行</p><p>查看运行结果</p><p>在web端：</p><p><img src="http://pv4lxcno2.bkt.clouddn.com/blog/20190725/4wgLyU3syVSv.png?imageslim" alt="mark"></p><p>part-r-00000这个就是运行出来的结果</p><p>我们可以使用命令行查看结果也可以把这个文件下载到本地，这里我们使用命令行查看</p><p>输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs -cat /output/part-r-00000</span><br></pre></td></tr></table></figure><p>返回如下结果</p><p><img src="http://pv4lxcno2.bkt.clouddn.com/blog/20190725/FHhHjKyLhTk9.png?imageslim" alt="mark"></p><p>到这里基本可以了，我们的hadoop已经安装配置好了，可以进行下一步的学习了</p><p>关于MapReduce的WordCount程序详解可以看这个</p><p><a href="https://blog.csdn.net/gulu_gulu_jp/article/details/51298164/" target="_blank" rel="noopener">https://blog.csdn.net/gulu_gulu_jp/article/details/51298164/</a></p><p>本次伪分布的配置就到这里了，如果还有问题可以向我留言，谢谢阅读，下次的文章应该是完全分布式的hadoop的安装教程了</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;本文介绍的主要是Hadoop的伪分布式的搭建以及遇到的相关问题的解决，做一下记录，jdk的安装这里就不做太多的介绍了，相信大家根据网上的安装
      
    
    </summary>
    
      <category term="搭建自己的hadoop学习集群" scheme="www.nghqqa.cn/categories/%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84hadoop%E5%AD%A6%E4%B9%A0%E9%9B%86%E7%BE%A4/"/>
    
    
      <category term="hadoop" scheme="www.nghqqa.cn/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="www.nghqqa.cn/2019/07/22/hello-world/"/>
    <id>www.nghqqa.cn/2019/07/22/hello-world/</id>
    <published>2019-07-21T23:42:50.603Z</published>
    <updated>2019-07-25T13:27:10.775Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
