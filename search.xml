<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[使用的hadoop相关安装包]]></title>
    <url>%2F2019%2F08%2F14%2F%E4%BD%BF%E7%94%A8%E7%9A%84hadoop%E7%9B%B8%E5%85%B3%E5%AE%89%E8%A3%85%E5%8C%85%2F</url>
    <content type="text"><![CDATA[前言这里放一些之前安装用到的安装包 链接：https://pan.baidu.com/s/1_qp_AKhRJNvzr6P63nJ9Rw提取码：7s9n hadoop spark hive scala 2.7.2 spark-2.4.0 hive-1.1.0 scala-2.11.4]]></content>
      <categories>
        <category>相关安装包</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scala的安装]]></title>
    <url>%2F2019%2F08%2F13%2Fscala%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[前言之前写的spark的安装中忘记说明安装spark要先安装scala，因为spark的底层是使用scala脚本语言开发 使用版本 scala-2.11.4 安装spark上传解压sparkspark的压缩包上传到我们的/opt/software上，解压到/opt/module/ 代码如下 1tar -zxf scala-2.11.4.tgz -C /opt/module/ 配置环境变量1vim /etc/profile 在末尾添加 123#scalaexport SCALA_HOME=/opt/module/scala-2.11.4export PATH=$PATH:$SCALA_HOME/bin 记得保存使其生效 1source /etc/profile 验证输入 1scala -version 出现 1Scala code runner version 2.11.4 -- Copyright 2002-2013, LAMP/EPFL 则代表安装完成 之后在其他两个节点中重复上述步骤！ 安装scala到这里也就完成，一定要安装完scala后去安装spark，谢谢大家的阅读。]]></content>
      <categories>
        <category>搭建自己的hadoop学习集群</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spark安装]]></title>
    <url>%2F2019%2F08%2F13%2Fspark%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[前言——spark介绍Apache Spark 是专为大规模数据处理而设计的快速通用的计算引擎，是类似于Hadoop MapReduce的通用并行框架。Spark拥有Hadoop MapReduce所具有的优点，但不同于MapReduce的是——Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的MapReduce的算法。Spark实际上是对Hadoop的一种补充，可以很好的在Hadoop 文件系统中并行运行。 安装spark 安装版本 spark-2.4.0 上传解压spark我们将spark上传到/opt/software下，之后将其解压到/opt/module/ 解压代码如下 1tar -zxf spark-2.4.0-bin-hadoop2.7.tgz -C /opt/module/ 修改名称 1mv spark-2.4.0-bin-hadoop2.7 spark-2.4.0 配置环境变量在/etc/profile文件的最后添加 12export SPARK_HOME=/opt/module/spark-2.4.0export PATH=$PATH:$SPARK_HOME/bin 记得保存 1source /etc/profile 修改spark-env.sh文件进入spark文件夹下的conf文件夹，修改文件名 1mv spark-env.sh.template spark-env.sh 改完之后 1vim spark-env.sh 在spark-env.sh文件的末尾添加 1234export JAVA_HOME=/opt/module/jdk1.8.0_191export SCALA_HOME=/opt/module/scala-2.11.4export HADOOP_HOME=/opt/module/hadoop-2.7.2export HADOOP_CONF_DIR=/opt/module/hadoop-2.7.2/etc/hadoop 修改 slaves 修改 slaves 文件： 1mv slaves.template slaves 打开 slaves 文件： 1vim slaves 添加以下内容： 123hadoop102hadoop103hadoop104 完成后，我们将spark文件夹传给slave1和slave2 输入（传输的时候要在spark-2.4.0的上一目录下传输） 12scp -r spark-2.4.0 root@salve1:/opt/module/scp -r spark-2.4.0 root@salve2:/opt/module/ 传输完成，在slave1和slave2中配置环境变量 启动spark在spark-2.4.0目录下输入 1sbin/start-all.sh 启动完成后，如果可以访问 http://192.168.128.172:8080/ 如图 则为成功 到这里spark的安装也就完成了，谢谢大家的阅读。]]></content>
      <categories>
        <category>搭建自己的hadoop学习集群</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hive的安装]]></title>
    <url>%2F2019%2F08%2F13%2Fhive%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[前言——hive介绍Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过和SQL类似的HiveQL语言快速实现简单的MapReduce统计,不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。同时，这个语言也允许熟悉 MapReduce 开发者的开发自定义的 mapper 和 reducer 来处理内建的 mapper 和 reducer 无法完成的复杂的分析工作。 Hive 没有专门的数据格式。所有Hive 的数据都存储在Hadoop兼容的文件系统（例如HDFS）中。Hive 在加载数据过程中不会对数据进行任何的修改，只是将数据移动到HDFS中Hive 设定的目录下，因此，Hive 不支持对数据的改写和添加，所有的数据都是在加载的时候确定的。 附一张hadoop的生态圈图 安装hivehive的安装基于之前的搭建的hadoop完全分布式集群，只需要安装在hadoop102上就行 安装hive版本 hive-1.1.0 上传解压hive我们将hive上传到/opt/software下，之后将其解压到/opt/module/ 解压代码如下 1tar -zxf apache-hive-1.1.0-bin.tar.gz -C /opt/module/ 解压完成后我们修改hive的文件名 1mv apache-hive-1.1.0-bin.tar.gz hive-1.1.0 修改文件名是为了让我们在配置环境变量时更加的方便 配置环境变量在/etc/profile文件的最后添加 12export HIVE_HOME=/opt/module/hive-1.1.0export PATH=$PATH:$HIVE_HOME/sbin 配置完成后，记得保存使其生效 输入 1source /etc/profile 安装mysqlhive它有自己的内置数据库derby，但是hive 使用derby 数据库存在不支持多个连接的问题，所以我们一般会使用mysql来代替hive的元数据库 123456789101112131415161718192021[root@hadoop102 ~]# cd /opt/module/src/[root@hadoop102 src]# wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm[root@hadoop102 src]# rpm -ivh mysql-community-release-el7-5.noarch.rpm[root@hadoop102 src]# yum install mysql-community-server# 这里时间较长，耐心等待...# 安装完成后，重启服务[root@hadoop102 src]# service mysqld restart[root@hadoop102 src]# mysqlWelcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 3Server version: 5.6.42 MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respective owners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.mysql&gt;# mysql安装成功 同时我们还需要去网上下载mysql的驱动包（mysql-connector-java.jar）把这个驱动包放置在hive目录下的lib目录下。 修改hive-site.xmlhive的配置文件放置在/opt/module/hive-1.1.0/conf下 配置hive-site.xml(conf中可能没有这个文件，我们使用vim打开时，没有的话，vim会帮我们自动创建) 1vim hive-site.xml 在文件中添加 123456789101112131415161718192021222324252627282930313233343536&lt;?xml version=&quot;1.0&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt;&lt;property&gt;&lt;name&gt;hive.metastore.local&lt;/name&gt;&lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;&lt;value&gt;jdbc:mysql://master:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;&lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;&lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;&lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;&lt;value&gt;root&lt;/value&gt;&lt;description&gt;username to use against metastore database&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;&lt;value&gt;hivepwd&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; 修改hive-env.sh1[root@hadoop102 conf]# mv hive-env.sh.template hive-env.sh 在文件最后添加 12export JAVA_HOME=/opt/module/jdk1.8.0_191export HADOOP_HOME=/opt/module/hadoop-2.7.2 配置mysql 创建数据库 hive ，用来保存 Hive 元数据： 1create database hive; 同时使 root 用户可以操作数据库 hive 中的所有表： 1GRANT all ON hive.* TO root@&apos;Hadoop102&apos; IDENTIFIED BY &apos;hivepwd&apos;; 1flush privileges; 这样Hive 的元数据库就安装完成。 测试hive安装是否成功启动Hadoop与mysql 输入hive 进入hive，出现命令行就说明之前搭建是成功的 12[root@Hadoop102 ]# hivehive&gt; 测试进入Hive 命令行 执行命令 创建一个名为 test 的表 查询该表的记录数： 12create table test(id int);select count(*) from test; 如果查询结果为0，则成功 到这里，hive的安装也就完成了，谢谢大家的阅读。]]></content>
      <categories>
        <category>搭建自己的hadoop学习集群</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop完全分布式安装]]></title>
    <url>%2F2019%2F08%2F10%2Fhadoop%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[前言我们之前搭建了hadoop的伪分布式的集群，伪分布式的集群对于学习一些基础的hadoop操作是足够的，但是当你涉及到更复杂的操作时，伪分布式就不够了，完全分布式的性能比伪分布的要强，而且完全分布式可操作性也更高，与此同时完全分布式对于电脑的配置也要求更高，完全分布式一般需要3台虚拟机来完成,下面我们开始搭建自己的完全分布式。 使用环境下面是本次搭建使用的环境 操作环境 主机名 IP地址 jdk hadoop版本 centos6.8 hadoop102 192.168.128.172 jdk1.8.0_191 hadoop-2.7.2 hadoop103 192.168.128.173 hadoop104 192.168.128.174 ​ 本文中使用的各种包，后续我会进行上传，以方便读者的使用 搭建步骤详解1.修改各节点的网络配置在虚拟机中输入 1vim /etc/sysconfig/network-scripts/ifcfg-eth0 可以进入虚拟机的网卡配置 我们需要修改虚拟机的网卡默认配置，将我们的虚拟机的网卡配置设置为静态ip ip地址 根据 VMware 虚拟网络进行相关配置 如图 在虚拟机里修改配置可以如图所示 修改完输入 1service network restart 重启网络服务 对其他两个hadoop节点也同样做上述操作，只不过在IPADDR值不一样，分别填其节点对应的ip 2.修改节点主机名，并且添加各节点映射在命令行中输入 1vim /etc//sysconfig/network 进入文件中修改hostname名称，如图所示 在其他两个子节点的hostname处分别填hadoop103和hadoop104 添加节点映射，输入 1vim /etc/hosts 添加节点映射为 我这里是多写了一些，对于这次搭建我们只需要添加hadoop102，hadoop103，hadoop104的节点映射即可 3.关闭防火墙我们只有关闭防火墙后才能在三台机器之间互相通信 所以关闭防火墙是很有必要的 我们可以使用这条命令来检查我们虚拟机开机时的防火墙状态 1chkconfig iptables --list 如果是已经关闭应该会如下图所示 如果没有关闭我们可以使用这两条命令来关闭我们的防火墙 1service iptables stop 这条命令是在本次虚拟机开启过程中关闭防火墙，也就是一次性关闭 我们还需要这条命令 1chkconfig iptables off 禁止防火墙关机自启动，这样防火墙就是是关闭了 当hadoop102关闭防火墙后，对于hadoop103与hadoop104也要做同样的操作 在防火墙关闭完成后，输入 1reboot 重启虚拟机，检查防火墙是否已经关闭 4.配置节点间ssh免密登陆在hadoop102上输入 1ssh-keygen -t rsa 一直按回车 完成后在保证三台虚拟机开启且完成之前所有配置的情况下输入 123[root@hadoop102 ~]# ssh-copy-id hadoop102[root@hadoop102 ~]# ssh-copy-id hadoop103[root@hadoop102 ~]# ssh-copy-id hadoop104 在hadoop102上完成后，在其他两个节点上重复上述操作 验证ssh免密登录是否成功 这里可以看到我们可以自己使用ssh转到hadoop103这台机器上 5.安装java和hadoop我们先使用xftp将hadoop和java的压缩包上传到我们新建的/opt/software上同时新建一个module文件夹放置解压后的hadoop和java，新建文件夹代码如下 123[root@hadoop102 ~]# cd /opt/[root@hadoop102 ~]# mkdir software[root@hadoop102 ~]# mkdir module 上传完成之后我们需要解压java和hadoop到/opt/module下，以便未来的管理 解压代码如下 12tar -zxf jdk-8u191-linux-x64.tar.gz -C /opt/module/tar -zxf hadoop-2.7.2.tar.gz -C /opt/module/ 解压完成后在/opt/module下应该是这样的，如图所示 之后我们就需要配置环境变量 1vi /etc/profile 在最后添加 123456export JAVA_HOME=/opt/module/jdk1.8.0_191export PATH=$PATH:$JAVA_HOME/binexport HADOOP_HOME=/opt/module/hadoop-2.7.2export PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbin 退出后，输入 1source /etc/profile 使其生效 验证java和hadoop环境变量是否配置完成 123456789101112[root@hadoop103 module]# java -versionjava version &quot;1.8.0_191&quot;Java(TM) SE Runtime Environment (build 1.8.0_191-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)[root@hadoop103 module]# hadoop versionHadoop 2.7.2Subversion Unknown -r UnknownCompiled by root on 2017-05-22T10:49ZCompiled with protoc 2.5.0From source with checksum d0fda26633fa762bff87ec759ebe689cThis command was run using /opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar[root@hadoop103 module]# 环境变量已经配置完成， 在其他两个节点上重复上述操作 6.配置hadoop中的文件6.1配置文件core-site.xmlcore-site.xml文件包含了NameNode主机地址，监听端口等信息，对于这个伪分布式模型来说，我的主机地址为hadoo101，NameNode默认使用的端口为8020。 修改core-site.xml 123456789101112&lt;configuration&gt;&lt;!-- 指定HDFS中NameNode的地址 --&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop101:8020&lt;/value&gt;&lt;/property&gt; &lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 6.2配置文件hdfs-site.xmlhdfs-site.xml用于配置/HDFS的相关属性，例如数据块的副本参数，数据块的副本对于完全分布式来说应该为3 12345678910111213&lt;configuration&gt;&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;hadoop104:50090&lt;/value&gt;&lt;/property&gt; &lt;/configuration&gt; 6.3配置文件slavesslaves文件里面记录的是集群里所有DataNode的主机名 1234[root@hadoop102 ~]#vim slaveshadoop102hadoop103hadoop104 6.4配置文件yarn-site.xml1234567891011121314&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt;&lt;!-- reducer获取数据的方式 --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;!-- 指定YARN的ResourceManager的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop103&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 6.5配置文件yarn-env.sh在其中修改java的路径 1export JAVA_HOME=/opt/module/jdk1.8.0_191 6.6配置hadoop-env.shhadoop-env.sh 由于Hadoop是java进程，所以需要添加jdk 修改hadoop-env.sh 1export JAVA_HOME=/opt/module/jdk1.8.0_191 6.7配置文件mapred-site.xml先改名，因为本身是没有mapred-site.xml这个文件的 输入 1mv mapred-site.xml.template mapred-site.xml 改名完成后 123456789[root@hadoop102 ~]#vim mapred-site.xml&lt;configuration&gt;&lt;!-- 指定mr运行在yarn上 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 这些配置文件改好后，返回/opt/module目录下 把hadoop102下修改的文件分发到hadoop103和hadoop104下 12[root@hadoop102 module]# scp -r hadoop root@hadoop103:/opt/module/[root@hadoop102 module]# scp -r hadoop root@hadoop104:/opt/module/ 7.测试集群在完成配置文件等一系列工作后，我们要开始测试集群了 先格式化 1[root@hadoop2 hadoop-2.7.2]# bin/hdfs namenode –format 之后启动hdfs 123456789101112131415[root@hadoop2 hadoop-2.7.2]# sbin/start-dfs.sh[root@hadoop2 hadoop-2.7.2]# jps4166 NameNode4482 Jps4263 DataNode[root@hadoop3 桌面]# jps3218 DataNode3288 Jps[root@hadoop4 桌面]# jps3221 DataNode3283 SecondaryNameNode3364 Jps 如果是这样这表示启动hdfs成功 下面启动yarn 1sbin/start-yarn.sh 启动完成后 在浏览器上访问可视化页面：http://192.168.128.172:50070 到此为止，hadoop配置就结束了，谢谢大家的阅读。]]></content>
      <categories>
        <category>搭建自己的hadoop学习集群</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux学习]]></title>
    <url>%2F2019%2F08%2F06%2FLinux%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[前言对于之前写的hadoop伪分布式的安装文章，可能对一些没有Linux基础的读者来说有一些的难度，所以建议大家先了解Linux的一些基础知识在来看之前的文章，可能就会觉得很简单了 学习建议我个人是比较推荐大家可以去b站看看韩顺平老师的Linux教程，可以在b站直接找到，这里放出b站链接 https://www.bilibili.com/video/av21303002?from=search&amp;seid=3872508779266125537 视频是18年上传的，但是知识是不会过时的，当然如果大家不想那么系统的了解Linux的话，可以去看看这个老哥的博客文章，这里放出链接 https://blog.csdn.net/weixin_41710054/article/details/89081599#22_vivim_19 这个文章写的比较的细，基本不知道的命令或者是快捷键都可以去文章中看看，自己看文章学习，可以比看视频省下不少时间，里面的命令可以基本满足正常操作Linux系统的要求。 好的，本次Linux的学习建议就到这里了，希望大家生活愉快。]]></content>
      <categories>
        <category>自己学习Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop伪分布式安装]]></title>
    <url>%2F2019%2F07%2F25%2Fhadoop%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[前言本文介绍的主要是Hadoop的伪分布式的搭建以及遇到的相关问题的解决，做一下记录，jdk的安装这里就不做太多的介绍了，相信大家根据网上的安装介绍很快就能安装成功。 hadoop集群分为3种模型 单机模型：测试使用 伪分布式模型：运行于单机 完全分布式模型：适用于多台机器 以下是使用的环境 操作环境 主机名 IP地址 jdk hadoop版本 centos6.8 hadoop101 192.168.128.171 jdk1.8.0_191 hadoop-2.7.2 本文中使用的各种包，后续我会进行上传，以方便读者的使用 安装hadoophadoop上传与解压​ 当我们配置好自己的虚拟机后，可以自行在网上下载xftp和xshell，来对于自己的虚拟机进行远程上传文件和远程操作，这两款软件对于学生而言都是免费的，大家可以自行在网站上下载，速度可能会有点慢。 ​ 当我们下载好这两款软件后，就可以将hadoop的解压包上传至自己的虚拟机上去，我们将解压包上传至/opt/software中，开始解压hadoop，将hadoop解压至/opt/module/中，同时建议将java也解压至/opt/module/中，方便后面的管理。 配置环境变量1vi /etc/profile 具体配置 在/etc/profile的最后面加上，关于vi编辑器的用法可以自行百度一下，简单用法应该几分钟就能学会 123456export JAVA_HOME=/opt/module/jdk1.8.0_191export PATH=$PATH:$JAVA_HOME/binexport HADOOP_HOME=/opt/module/hadoop-2.7.2export PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbin 在配置环境变量完成后，记得要进行让它生效 输入 1source /etc/profile 即可生效 可以输入 1hadoop version 如果成功则显示 123456Hadoop 2.7.2Subversion Unknown -r UnknownCompiled by root on 2017-05-22T10:49ZCompiled with protoc 2.5.0From source with checksum d0fda26633fa762bff87ec759ebe689cThis command was run using /opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar 到这里hadoop就算是安装好了 配置hadoop在伪分布式里我们只需要改三个配置文件core-site.xml和hdfs-site.xml还有hadoop-env.sh 这三个文件在hadoop目录下的etc/hadoop文件夹下 core-site.xml文件包含了NameNode主机地址，监听端口等信息，对于这个伪分布式模型来说，我的主机地址为hadoo101，NameNode默认使用的端口为8020。 修改core-site.xml 123456789101112&lt;configuration&gt;&lt;!-- 指定HDFS中NameNode的地址 --&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop101:8020&lt;/value&gt;&lt;/property&gt; &lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xml用于配置/HDFS的相关属性，例如数据块的副本参数，数据块的副本对于伪分布式来说应该为1 修改hdfs-site.xml 1234567&lt;configuration&gt;&lt;!-- 指定HDFS副本的数量 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hadoop-env.sh 由于Hadoop是java进程，所以需要添加jdk 修改hadoop-env.sh 1export JAVA_HOME=/opt/module/jdk1.8.0_191 对于伪分布式来说，改这三个配置文件够了。 在配置文件完成后，我们需要对hadoop进行初始化 在hadoop-2.7.2的目录下输入 1bin/hdfs namenode -format 如果初始化成功的话，一个和下图相似 到这里hadoop的配置就已经完成了 启动集群在hadoop-2.7.2目录下输入 1sbin/start-dfs.sh 启动dfs 输入 1sbin/start-yarn.sh 启动yarn节点 启动成功应该和下图相似 到这里我们的集群就算是启动成功了 我们可以在web端查看HDFS文件系统 http://192.168.128.171:50070 192.168.128.171是我的ip地址，如果配置的不同，改一下即可 web端的hdfs文件系统如下图所示 测试集群在HDFS文件系统上创建一个input文件夹 输入 1hadoop fs -mkdir /input 在web端应该可以看到 我们上传一个文件看看 1hadoop fs -put LICENSE.txt /input LICENSE.txt是hadoop自带的一个TXT文件 如果上传成功在web端应该可以看到 这样就是上传成功了 我们在HDFS上跑一下MapReduce程序 输入 1hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /input/LICENSE.txt /output 这里说明一下MapReduce要在启动yarn下运行 查看运行结果 在web端： part-r-00000这个就是运行出来的结果 我们可以使用命令行查看结果也可以把这个文件下载到本地，这里我们使用命令行查看 输入 1bin/hdfs dfs -cat /output/part-r-00000 返回如下结果 到这里基本可以了，我们的hadoop已经安装配置好了，可以进行下一步的学习了 关于MapReduce的WordCount程序详解可以看这个 https://blog.csdn.net/gulu_gulu_jp/article/details/51298164/ 本次伪分布的配置就到这里了，如果还有问题可以向我留言，谢谢阅读，下次的文章应该是完全分布式的hadoop的安装教程了]]></content>
      <categories>
        <category>搭建自己的hadoop学习集群</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F07%2F22%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
