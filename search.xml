<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[hadoop完全分布式安装]]></title>
    <url>%2F2019%2F08%2F10%2Fhadoop%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[前言我们之前搭建了hadoop的伪分布式的集群，伪分布式的集群对于学习一些基础的hadoop操作是足够的，但是当你涉及到更复杂的操作时，伪分布式就不够了，完全分布式的性能比伪分布的要强，而且完全分布式可操作性也更高，与此同时完全分布式对于电脑的配置也要求更高，完全分布式一般需要3台虚拟机来完成,下面我们开始搭建自己的完全分布式。 使用环境下面是本次搭建使用的环境 操作环境 主机名 IP地址 jdk hadoop版本 centos6.8 hadoop102 192.168.128.172 jdk1.8.0_191 hadoop-2.7.2 hadoop103 192.168.128.173 hadoop104 192.168.128.174 ​ 本文中使用的各种包，后续我会进行上传，以方便读者的使用 搭建步骤详解1.修改各节点的网络配置在虚拟机中输入 1vim /etc/sysconfig/network-scripts/ifcfg-eth0 可以进入虚拟机的网卡配置 我们需要修改虚拟机的网卡默认配置，将我们的虚拟机的网卡配置设置为静态ip ip地址 根据 VMware 虚拟网络进行相关配置 如图 在虚拟机里修改配置可以如图所示 修改完输入 1service network restart 重启网络服务 对其他两个hadoop节点也同样做上述操作，只不过在IPADDR值不一样，分别填其节点对应的ip 2.修改节点主机名，并且添加各节点映射在命令行中输入 1vim /etc//sysconfig/network 进入文件中修改hostname名称，如图所示 在其他两个子节点的hostname处分别填hadoop103和hadoop104 添加节点映射，输入 1vim /etc/hosts 添加节点映射为 我这里是多写了一些，对于这次搭建我们只需要添加hadoop102，hadoop103，hadoop104的节点映射即可 3.关闭防火墙我们只有关闭防火墙后才能在三台机器之间互相通信 所以关闭防火墙是很有必要的 我们可以使用这条命令来检查我们虚拟机开机时的防火墙状态 1chkconfig iptables --list 如果是已经关闭应该会如下图所示 如果没有关闭我们可以使用这两条命令来关闭我们的防火墙 1service iptables stop 这条命令是在本次虚拟机开启过程中关闭防火墙，也就是一次性关闭 我们还需要这条命令 1chkconfig iptables off 禁止防火墙关机自启动，这样防火墙就是是关闭了 当hadoop102关闭防火墙后，对于hadoop103与hadoop104也要做同样的操作 在防火墙关闭完成后，输入 1reboot 重启虚拟机，检查防火墙是否已经关闭 4.配置节点间ssh免密登陆在hadoop102上输入 1ssh-keygen -t rsa 一直按回车 完成后在保证三台虚拟机开启且完成之前所有配置的情况下输入 123[root@hadoop102 ~]# ssh-copy-id hadoop102[root@hadoop102 ~]# ssh-copy-id hadoop103[root@hadoop102 ~]# ssh-copy-id hadoop104 在hadoop102上完成后，在其他两个节点上重复上述操作 验证ssh免密登录是否成功 这里可以看到我们可以自己使用ssh转到hadoop103这台机器上 5.安装java和hadoop我们先使用xftp将hadoop和java的压缩包上传到我们新建的/opt/software上同时新建一个module文件夹放置解压后的hadoop和java，新建文件夹代码如下 123[root@hadoop102 ~]# cd /opt/[root@hadoop102 ~]# mkdir software[root@hadoop102 ~]# mkdir module 上传完成之后我们需要解压java和hadoop到/opt/module下，以便未来的管理 解压代码如下 12tar -zxf jdk-8u191-linux-x64.tar.gz -C /opt/module/tar -zxf hadoop-2.7.2.tar.gz -C /opt/module/ 解压完成后在/opt/module下应该是这样的，如图所示 之后我们就需要配置环境变量 1vi /etc/profile 在最后添加 123456export JAVA_HOME=/opt/module/jdk1.8.0_191export PATH=$PATH:$JAVA_HOME/binexport HADOOP_HOME=/opt/module/hadoop-2.7.2export PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbin 退出后，输入 1source /etc/profile 使其生效 验证java和hadoop环境变量是否配置完成 123456789101112[root@hadoop103 module]# java -versionjava version &quot;1.8.0_191&quot;Java(TM) SE Runtime Environment (build 1.8.0_191-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)[root@hadoop103 module]# hadoop versionHadoop 2.7.2Subversion Unknown -r UnknownCompiled by root on 2017-05-22T10:49ZCompiled with protoc 2.5.0From source with checksum d0fda26633fa762bff87ec759ebe689cThis command was run using /opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar[root@hadoop103 module]# 环境变量已经配置完成， 在其他两个节点上重复上述操作 6.配置hadoop中的文件6.1配置文件core-site.xmlcore-site.xml文件包含了NameNode主机地址，监听端口等信息，对于这个伪分布式模型来说，我的主机地址为hadoo101，NameNode默认使用的端口为8020。 修改core-site.xml 123456789101112&lt;configuration&gt;&lt;!-- 指定HDFS中NameNode的地址 --&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop101:8020&lt;/value&gt;&lt;/property&gt; &lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 6.2配置文件hdfs-site.xmlhdfs-site.xml用于配置/HDFS的相关属性，例如数据块的副本参数，数据块的副本对于完全分布式来说应该为3 12345678910111213&lt;configuration&gt;&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;hadoop104:50090&lt;/value&gt;&lt;/property&gt; &lt;/configuration&gt; 6.3配置文件slavesslaves文件里面记录的是集群里所有DataNode的主机名 1234[root@hadoop102 ~]#vim slaveshadoop102hadoop103hadoop104 6.4配置文件yarn-site.xml1234567891011121314&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt;&lt;!-- reducer获取数据的方式 --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;!-- 指定YARN的ResourceManager的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop103&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 6.5配置文件yarn-env.sh在其中修改java的路径 1export JAVA_HOME=/opt/module/jdk1.8.0_191 6.6配置hadoop-env.shhadoop-env.sh 由于Hadoop是java进程，所以需要添加jdk 修改hadoop-env.sh 1export JAVA_HOME=/opt/module/jdk1.8.0_191 6.7配置文件mapred-site.xml先改名，因为本身是没有mapred-site.xml这个文件的 输入 1mv mapred-site.xml.template mapred-site.xml 改名完成后 123456789[root@hadoop102 ~]#vim mapred-site.xml&lt;configuration&gt;&lt;!-- 指定mr运行在yarn上 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 这些配置文件改好后，返回/opt/module目录下 把hadoop102下修改的文件分发到hadoop103和hadoop104下 12[root@master module]# scp -r hadoop root@hadoop103:/opt/module/[root@master module]# scp -r hadoop root@hadoop104:/opt/module/ 7.测试集群在完成配置文件等一系列工作后，我们要开始测试集群了 先格式化 1[root@hadoop2 hadoop-2.7.2]# bin/hdfs namenode –format 之后启动hdfs 123456789101112131415[root@hadoop2 hadoop-2.7.2]# sbin/start-dfs.sh[root@hadoop2 hadoop-2.7.2]# jps4166 NameNode4482 Jps4263 DataNode[root@hadoop3 桌面]# jps3218 DataNode3288 Jps[root@hadoop4 桌面]# jps3221 DataNode3283 SecondaryNameNode3364 Jps 如果是这样这表示启动hdfs成功 下面启动yarn 1sbin/start-yarn.sh 启动完成后 在浏览器上访问可视化页面：http://192.168.128.172:50070 到此为止，hadoop配置就结束了，谢谢大家的阅读。]]></content>
      <categories>
        <category>搭建自己的hadoop学习集群</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux学习]]></title>
    <url>%2F2019%2F08%2F06%2FLinux%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[前言对于之前写的hadoop伪分布式的安装文章，可能对一些没有Linux基础的读者来说有一些的难度，所以建议大家先了解Linux的一些基础知识在来看之前的文章，可能就会觉得很简单了 学习建议我个人是比较推荐大家可以去b站看看韩顺平老师的Linux教程，可以在b站直接找到，这里放出b站链接 https://www.bilibili.com/video/av21303002?from=search&amp;seid=3872508779266125537 视频是18年上传的，但是知识是不会过时的，当然如果大家不想那么系统的了解Linux的话，可以去看看这个老哥的博客文章，这里放出链接 https://blog.csdn.net/weixin_41710054/article/details/89081599#22_vivim_19 这个文章写的比较的细，基本不知道的命令或者是快捷键都可以去文章中看看，自己看文章学习，可以比看视频省下不少时间，里面的命令可以基本满足正常操作Linux系统的要求。 好的，本次Linux的学习建议就到这里了，希望大家生活愉快。]]></content>
      <categories>
        <category>自己学习Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop伪分布式安装]]></title>
    <url>%2F2019%2F07%2F25%2Fhadoop%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[前言本文介绍的主要是Hadoop的伪分布式的搭建以及遇到的相关问题的解决，做一下记录，jdk的安装这里就不做太多的介绍了，相信大家根据网上的安装介绍很快就能安装成功。 hadoop集群分为3种模型 单机模型：测试使用 伪分布式模型：运行于单机 完全分布式模型：适用于多台机器 以下是使用的环境 操作环境 主机名 IP地址 jdk hadoop版本 centos6.8 hadoop101 192.168.128.171 jdk1.8.0_191 hadoop-2.7.2 本文中使用的各种包，后续我会进行上传，以方便读者的使用 安装hadoophadoop上传与解压​ 当我们配置好自己的虚拟机后，可以自行在网上下载xftp和xshell，来对于自己的虚拟机进行远程上传文件和远程操作，这两款软件对于学生而言都是免费的，大家可以自行在网站上下载，速度可能会有点慢。 ​ 当我们下载好这两款软件后，就可以将hadoop的解压包上传至自己的虚拟机上去，我们将解压包上传至/opt/software中，开始解压hadoop，将hadoop解压至/opt/module/中，同时建议将java也解压至/opt/module/中，方便后面的管理。 配置环境变量1vi /etc/profile 具体配置 在/etc/profile的最后面加上，关于vi编辑器的用法可以自行百度一下，简单用法应该几分钟就能学会 123456export JAVA_HOME=/opt/module/jdk1.8.0_191export PATH=$PATH:$JAVA_HOME/binexport HADOOP_HOME=/opt/module/hadoop-2.7.2export PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbin 在配置环境变量完成后，记得要进行让它生效 输入 1source /etc/profile 即可生效 可以输入 1hadoop version 如果成功则显示 123456Hadoop 2.7.2Subversion Unknown -r UnknownCompiled by root on 2017-05-22T10:49ZCompiled with protoc 2.5.0From source with checksum d0fda26633fa762bff87ec759ebe689cThis command was run using /opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar 到这里hadoop就算是安装好了 配置hadoop在伪分布式里我们只需要改三个配置文件core-site.xml和hdfs-site.xml还有hadoop-env.sh 这三个文件在hadoop目录下的etc/hadoop文件夹下 core-site.xml文件包含了NameNode主机地址，监听端口等信息，对于这个伪分布式模型来说，我的主机地址为hadoo101，NameNode默认使用的端口为8020。 修改core-site.xml 123456789101112&lt;configuration&gt;&lt;!-- 指定HDFS中NameNode的地址 --&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop101:8020&lt;/value&gt;&lt;/property&gt; &lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xml用于配置/HDFS的相关属性，例如数据块的副本参数，数据块的副本对于伪分布式来说应该为1 修改hdfs-site.xml 1234567&lt;configuration&gt;&lt;!-- 指定HDFS副本的数量 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hadoop-env.sh 由于Hadoop是java进程，所以需要添加jdk 修改hadoop-env.sh 1export JAVA_HOME=/opt/module/jdk1.8.0_191 对于伪分布式来说，改这三个配置文件够了。 在配置文件完成后，我们需要对hadoop进行初始化 在hadoop-2.7.2的目录下输入 1bin/hdfs namenode -format 如果初始化成功的话，一个和下图相似 到这里hadoop的配置就已经完成了 启动集群在hadoop-2.7.2目录下输入 1sbin/start-dfs.sh 启动dfs 输入 1sbin/start-yarn.sh 启动yarn节点 启动成功应该和下图相似 到这里我们的集群就算是启动成功了 我们可以在web端查看HDFS文件系统 http://192.168.128.171:50070 192.168.128.171是我的ip地址，如果配置的不同，改一下即可 web端的hdfs文件系统如下图所示 测试集群在HDFS文件系统上创建一个input文件夹 输入 1hadoop fs -mkdir /input 在web端应该可以看到 我们上传一个文件看看 1hadoop fs -put LICENSE.txt /input LICENSE.txt是hadoop自带的一个TXT文件 如果上传成功在web端应该可以看到 这样就是上传成功了 我们在HDFS上跑一下MapReduce程序 输入 1hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /input/LICENSE.txt /output 这里说明一下MapReduce要在启动yarn下运行 查看运行结果 在web端： part-r-00000这个就是运行出来的结果 我们可以使用命令行查看结果也可以把这个文件下载到本地，这里我们使用命令行查看 输入 1bin/hdfs dfs -cat /output/part-r-00000 返回如下结果 到这里基本可以了，我们的hadoop已经安装配置好了，可以进行下一步的学习了 关于MapReduce的WordCount程序详解可以看这个 https://blog.csdn.net/gulu_gulu_jp/article/details/51298164/ 本次伪分布的配置就到这里了，如果还有问题可以向我留言，谢谢阅读，下次的文章应该是完全分布式的hadoop的安装教程了]]></content>
      <categories>
        <category>搭建自己的hadoop学习集群</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F07%2F22%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
